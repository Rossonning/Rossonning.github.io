---
title: Nginx
categories: Middleware
tags:
- Middleware
---


# In General
Nginx（发音为"engine-x"）是一款高性能的开源Web服务器，也可以用作反向代理服务器、负载均衡器、HTTP缓存以及作为应用服务器的前端服务器。以下是Nginx的主要应用场景：

1. Web服务器：
- `静态资源服务`： Nginx 可以作为静态文件（如HTML、CSS、JavaScript、图像等）的高效服务器，提供快速的文件传输。
- `虚拟主机`： Nginx 允许配置多个虚拟主机，使得一台服务器可以托管多个网站。

2. 反向代理服务器：
- `负载均衡`： Nginx 可以分发客户端请求到多个应用服务器，以实现负载均衡，提高系统的可伸缩性和稳定性。
- `安全性`： 充当反向代理的 Nginx 可以隐藏后端服务器的实际IP地址，提高安全性

3. 缓存服务器：
- `HTTP缓存`： Nginx 可以缓存静态和动态内容，减轻后端服务器的负担，提高访问速度。
- `反向代理缓存`： 在反向代理模式下，Nginx 可以缓存后端服务器的响应，减轻服务器负载。

4. SSL/TLS终端：
- `SSL/TLS加速`： Nginx 可以作为SSL/TLS终端，负责SSL/TLS加解密，将加密负担从应用服务器上移除。

5. WebSocket支持：
- `WebSocket代理`： Nginx 可以代理 WebSocket 连接，使得应用程序可以使用 WebSocket 协议进行实时通信。

6. 容器化部署：
- `容器反向代理`： 在容器化环境中，Nginx 经常被用作容器之间的反向代理，协调和处理来自不同容器的流量。

8. 限速和限制访问：
- `流量控制`： Nginx 允许对访问速度进行限制，防止恶意或异常访问。
- `IP访问控制`： 可以根据IP地址、用户代理等进行访问控制。

9. 静态文件服务：
- `高并发文件服务`： 由于其出色的性能，Nginx 适合用作高并发的静态文件服务器。

## 和Tomcat服务器的对比

Tomcat和Nginx是两种不同类型的服务器，各自有着不同的定位和使用场景。以下是它们之间的一些区别和各自的优劣势：

Nginx：
- 是一个高性能的反向代理服务器、负载均衡器，以及静态文件服务器。
- 专注于处理并发连接、负载均衡和高效的静态文件服务。
- 通常用于反向代理，负载均衡，处理静态资源，SSL终端，以及作为Web服务器的入口。

Tomcat：
- 是一个Servlet容器，用于运行Java Servlet和JavaServer Pages（JSP）等Java技术的Web应用程序。
- 主要用于处理动态内容，执行Java代码，并生成动态的Web页面。
- 通常用于直接托管Java Web应用，处理与Java相关的逻辑。

## 反向代理

反向代理是一种网络服务架构，其中代理服务器接收来自客户端的请求，然后将这些请求转发给位于内部网络上的服务器，并将服务器的响应返回给客户端。
在这个过程中，`客户端并不直接与目标服务器通信`，而是与代理服务器进行通信，`因此代理服务器在客户端和目标服务器之间充当了“反向”的角色`。

和正向代理相比：
- 正向代理是客户端通过代理服务器访问其他服务器，代理服务器代表客户端发起请求，隐藏了请求方的客户端。

- 反向代理是客户端直接访问代理服务器，代理服务器代表服务器来处理客户端的请求，隐藏了返回结果的服务端。

> 正向代理因此实现了 匿名访问
> 而反向代理最大的优势在于 负载均衡等对后端服务器架构的简化

## VPN
VPN（Virtual Private Network，虚拟专用网络）通常被认为是一种`正向代理`技术。

VPN的主要目的是通过`加密`和`隧道技术`，使用户能够在不安全的网络上安全地传输数据。VPN可以提供许多功能，包括访问控制、安全性和隐私保护。

`加密和隧道：`
VPN使用加密算法来保护数据的机密性，以确保在公共网络上传输的数据是安全的。此外，VPN使用隧道协议将数据包装在加密的外壳中，以在公共网络上传输。

`认证和授权：`
VPN通过身份验证机制来验证用户或设备的身份。这可以通过用户名和密码、证书等方式进行。授权机制确保用户只能访问其被授权的资源。


## 负载均衡 与 K8S

在使用 Kubernetes（k8s）进行编排和部署时，通常可以使用 Kubernetes 内置的负载均衡和服务发现功能，而不必再依赖单独的 Nginx 负载均衡。Kubernetes 提供了一种称为 Service 的抽象，它可以自动实现负载均衡。

在这种情况下，你的Web应用可以通过一个 Kubernetes Service 暴露，该服务将请求转发到运行应用的 Pod。这允许你避免使用独立的Nginx负载均衡器，而是直接利用 Kubernetes 的负载均衡机制。

这样的方式有几个优势：

- `自动负载均衡`： Kubernetes会自动处理流量的负载均衡，无需手动配置。

- `服务发现`： 使用 Kubernetes Service 提供的 DNS 解析，其他服务可以通过 Service 的名称来发现和访问你的应用。

- `弹性伸缩`： 你可以根据流量的需求对 Deployment 进行弹性伸缩，而不需要手动调整负载均衡器的配置。

## CORS 和 Nginx
CORS（Cross-Origin Resource Sharing）是一个浏览器安全特性，它限制了一个页面中的Web应用程序从另一个源加载资源。
`"跨域"是指在浏览器的同一页面上加载来自不同域的资源。`
CORS是为了增加Web页面的安全性而设计的，因为它防止了一些潜在的安全威胁，如跨站请求伪造（CSRF）。

当一个网页从一个域（源）向另一个域请求资源时，浏览器会执行`同源策略`（Same-Origin Policy），`该策略会阻止页面读取来自不同源的数据`。而CORS通过服务器响应头的设置，允许服务器声明哪些域是被允许的，以解决这个问题。

### 域（Origin）
`Origin` 是指 Web 应用的源，通常由`协议、主机和端口`组成。
在 Web 开发中，我们经常谈论`同源策略`，这是浏览器实施的一项安全功能，它要求 Web 页面的所有资源都来自相同的源，即协议、主机和端口都一致。

一个典型的 `Origin` 形式如下：
```bash
https://www.example.com:443
```

同源策略限制了从一个源加载的文档或脚本如何与来自另一个源的资源进行交互。如果两个页面的 `Origin` 不同，那么它们就被认为是跨源的。

举个例子，假设你的前端代码运行在 `https://app.example.com`，而后端 API 运行在 `https://api.example.com`。
这两个域名就是不同的 `Origin` 。
由于同源策略，浏览器默认会阻止前端代码直接从 `https://app.example.com` 向 `https://api.example.com` 发起请求。

### Nginx如何解决这个问题
***1. 添加响应头：***
通过Nginx配置，在响应中添加合适的CORS头部信息，告诉浏览器哪些域是被允许的。以下是一个简单的Nginx配置：
```bash
location / {
    add_header 'Access-Control-Allow-Origin' '*';
    add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
    add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';
    
    if ($request_method = 'OPTIONS') {
        add_header 'Access-Control-Max-Age' 1728000;
        add_header 'Content-Type' 'text/plain; charset=utf-8';
        add_header 'Content-Length' 0;
        return 204;
    }

    # 这里配置代理到后端应用
    proxy_pass http://your-backend-server;
    # 其他配置...
}
```
这个配置表示`允许所有来源（*）的请求`，并且允许的方法包括GET、POST、OPTIONS。
这样，即使前端和后端不在同一域下，浏览器也会允许这些请求。

***2. 代理后端应用：***
在Nginx配置中，你会配置代理转发到后端应用的地址（proxy_pass http://your-backend-server;）。
这意味着所有的请求实际上都是从Nginx发起的，而不是从浏览器。
由于同源策略是在浏览器中执行的，因此在这个层面上，同源策略不再是一个问题，允许你在Nginx层面解决CORS问题。

这种方法的好处是，你无需修改你的应用代码。前端代码可以直接通过Nginx与后端通信，而不必担心跨域问题。
这也提供了更灵活的配置选项，你可以根据需要定制不同的CORS策略。

请注意，对于一些特殊场景或者更严格的安全需求，你可能需要更详细的配置，确保只有合法的请求被允许。



# Practice on Linux

# Practice on MacOS

通过homebrew安装后配置文件的路径：`/opt/homebrew/etc/nginx/nginx.conf`


```bash
# 如果 Nginx 在运行，它会返回一个或多个进程 ID。
pgrep nginx

# 这个命令用于测试配置文件的语法。如果 Nginx 正在运行，你应该会看到一条消息，表明配置文件语法是正确的
nginx -t


# nginx启动（需要已配置）
nginx

#
sudo nginx -s stop

sudo lsof -i :80

```


## 处理跨域
### 将前后端都代理到nginx端口
```conf
    server {
        listen 8080; # nginx监听的端口
        server_name localhost;
    
        location / { # 8080/
            # 配置前端代理
            proxy_pass http://localhost:3000;
            # proxy_set_header Host $host;
            # proxy_set_header X-Real-IP $remote_addr;
            # proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            # proxy_set_header X-Forwarded-Proto $scheme;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
    
    
            # 支持 OPTIONS 请求（预检请求）
            if ($request_method = 'OPTIONS') {
                return 204;
            }
        
        }
    
        location /api {
            # 配置后端代理
            proxy_pass http://localhost:8000/api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
```

